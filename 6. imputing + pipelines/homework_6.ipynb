{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "69df0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import KNNImputer\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "f22878db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.4'"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f1c1cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('avocado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "2fced1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- MISSING VALUES---\n",
    "#\n",
    "# we have no original missing values, so we'll pretend\n",
    "# we have those: select some columns to put data out of them randomly\n",
    "# chosen columns are 'AveragePrice', 'type' and randomly something from\n",
    "# '4046', '4225', '4770' and total amount respectively\n",
    "#\n",
    "#\n",
    "# type will be fixed using knnimputer\n",
    "# that depends on other numeric values - organic avocados\n",
    "# obviously have different statistics, unlike \n",
    "# conventional\n",
    "#\n",
    "# 4046, 4225, 4770 and total amount - using knn imputer\n",
    "# in spite of the fact that these values are strongly tied\n",
    "# on economic conditions, so e.g. equally wealthy areas are\n",
    "# very likely to have similar buy stats\n",
    "#\n",
    "# AveragePrice will be imputed by using mean value of\n",
    "# all table (tbh, for diversity)\n",
    "#\n",
    "#---PREPROCESSING---\n",
    "#\n",
    "# 1. type has 2 values, thus we can use one hot encoder\n",
    "# feature - nice way to turn 'object' into numeric here\n",
    "#\n",
    "# 2. index tells us nothing and should be dropped\n",
    "#\n",
    "# 3. date is not useful while it's object\n",
    "# no visible sense in storing day of observation\n",
    "# all the more there are a few unique day values per month\n",
    "# so let's create a column how many months passed since some moment\n",
    "# - object becomes ordinal feature\n",
    "#\n",
    "# 4. add column 'money spent' that is composition of 'Total Volume'\n",
    "# and 'AveragePrice' - gives us more details about money\n",
    "#\n",
    "# 5. amount of regions will be reduced to 10\n",
    "# say we have 100 avocado purchase stats where total money spent on avocado\n",
    "# is between 250 000 and 500 000; 70 of them is Texas\n",
    "# then we match 30 remaining as Texas too\n",
    "# and lets use one hot encoder after this step\n",
    "#\n",
    "# we lose some region data doing this step, but it's pretty likely to\n",
    "# appear a nice alternative to simple one hot encoder (too many columns),\n",
    "# to mean target encoding (we are losing region data totally)\n",
    "# to label encoding (we have no 'better' regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550ebca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "a192ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random data deletion\n",
    "df.loc[[random.randint(0, df.shape[0]) for i in range(0, int(0.15*df.shape[0]))], 'AveragePrice'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "33a22508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[random.randint(0, df.shape[0]) for i in range(0, int(0.15*df.shape[0]))], 'type'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "f51dd867",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols_to_del_from = ['4046', '4225', '4770']\n",
    "\n",
    "for i in range(0, int(0.15*df.shape[0])):\n",
    "    curr_col_to_del_ind = random.randint(0, 2)\n",
    "    curr_row_to_del_ind = random.randint(0, df.shape[0])\n",
    "    df.loc[curr_row_to_del_ind, cols_to_del_from[curr_col_to_del_ind]] = np.nan\n",
    "    df.loc[curr_row_to_del_ind, 'Total Volume'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "77cbc600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>1.63</td>\n",
       "      <td>17074.83</td>\n",
       "      <td>2046.96</td>\n",
       "      <td>1529.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13498.67</td>\n",
       "      <td>13066.82</td>\n",
       "      <td>431.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1191.70</td>\n",
       "      <td>3431.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9264.84</td>\n",
       "      <td>8940.04</td>\n",
       "      <td>324.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>13766.76</td>\n",
       "      <td>1191.92</td>\n",
       "      <td>2452.79</td>\n",
       "      <td>727.94</td>\n",
       "      <td>9394.11</td>\n",
       "      <td>9351.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16205.22</td>\n",
       "      <td>1527.63</td>\n",
       "      <td>2981.04</td>\n",
       "      <td>727.01</td>\n",
       "      <td>10969.54</td>\n",
       "      <td>10919.54</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>11</td>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>1.62</td>\n",
       "      <td>17489.58</td>\n",
       "      <td>2894.77</td>\n",
       "      <td>2356.13</td>\n",
       "      <td>224.53</td>\n",
       "      <td>12014.15</td>\n",
       "      <td>11988.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0          0  2015-12-27           NaN      64236.62  1036.74   54454.85   \n",
       "1          1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2          2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3          3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4          4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "...      ...         ...           ...           ...      ...        ...   \n",
       "18244      7  2018-02-04          1.63      17074.83  2046.96    1529.20   \n",
       "18245      8  2018-01-28          1.71           NaN  1191.70    3431.50   \n",
       "18246      9  2018-01-21          1.87      13766.76  1191.92    2452.79   \n",
       "18247     10  2018-01-14          1.93      16205.22  1527.63    2981.04   \n",
       "18248     11  2018-01-07          1.62      17489.58  2894.77    2356.13   \n",
       "\n",
       "         4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0       48.16     8696.87     8603.62       93.25          0.0           NaN   \n",
       "1       58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2      130.50     8145.35     8042.21      103.14          0.0           NaN   \n",
       "3       72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4       75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "...       ...         ...         ...         ...          ...           ...   \n",
       "18244    0.00    13498.67    13066.82      431.85          0.0           NaN   \n",
       "18245     NaN     9264.84     8940.04      324.80          0.0       organic   \n",
       "18246  727.94     9394.11     9351.80       42.31          0.0       organic   \n",
       "18247  727.01    10969.54    10919.54       50.00          0.0       organic   \n",
       "18248  224.53    12014.15    11988.14       26.01          0.0       organic   \n",
       "\n",
       "       year            region  \n",
       "0      2015            Albany  \n",
       "1      2015            Albany  \n",
       "2      2015            Albany  \n",
       "3      2015            Albany  \n",
       "4      2015            Albany  \n",
       "...     ...               ...  \n",
       "18244  2018  WestTexNewMexico  \n",
       "18245  2018  WestTexNewMexico  \n",
       "18246  2018  WestTexNewMexico  \n",
       "18247  2018  WestTexNewMexico  \n",
       "18248  2018  WestTexNewMexico  \n",
       "\n",
       "[18249 rows x 14 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n",
    "# Now we have data frame with missing values to impute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8516ba7",
   "metadata": {},
   "source": [
    "# Custom classes for pipeline construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "2247cf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conventional</th>\n",
       "      <td>23</td>\n",
       "      <td>1.13</td>\n",
       "      <td>412213.00</td>\n",
       "      <td>105339.580</td>\n",
       "      <td>138937.95</td>\n",
       "      <td>6107.57</td>\n",
       "      <td>100570.550</td>\n",
       "      <td>76008.080</td>\n",
       "      <td>14816.180</td>\n",
       "      <td>135.85</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organic</th>\n",
       "      <td>24</td>\n",
       "      <td>1.63</td>\n",
       "      <td>10676.48</td>\n",
       "      <td>889.605</td>\n",
       "      <td>3048.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5093.575</td>\n",
       "      <td>2880.095</td>\n",
       "      <td>380.075</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index  AveragePrice  Total Volume        4046       4225  \\\n",
       "type                                                                     \n",
       "conventional     23          1.13     412213.00  105339.580  138937.95   \n",
       "organic          24          1.63      10676.48     889.605    3048.57   \n",
       "\n",
       "                 4770  Total Bags  Small Bags  Large Bags  XLarge Bags  year  \n",
       "type                                                                          \n",
       "conventional  6107.57  100570.550   76008.080   14816.180       135.85  2016  \n",
       "organic          0.00    5093.575    2880.095     380.075         0.00  2016  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('type').agg('median')\n",
    "\n",
    "# statistics tell us we should impute 'type'\n",
    "# using data from 4225, 4046, 4770 - thats how we\n",
    "# 'calculate a probability' of certain avocado stats\n",
    "# to turn out to be about organic or conventional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0b5c3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeAvPriceByRegionMean(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Imputes 'AveragePrice' value by taking mean from all\n",
    "    values with same 'region' value in data frame\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initalizes a new instance of imputer\n",
    "        \"\"\"\n",
    "        TransformerMixin.__init__(self)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fits to X. Creates and remembers a new 'region' column,\n",
    "        setting off from dataset X.\n",
    "        \"\"\"\n",
    "        self.impute_dict = {}\n",
    "        self.missing_key_val = X['AveragePrice'].mean() \n",
    "        regions_list = list(X['region'].unique())\n",
    "        for reg in regions_list:\n",
    "            self.impute_dict[reg] = X[X['region'] == reg]['AveragePrice'].mean()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Writes previously created new 'region' column to X\n",
    "        \"\"\"\n",
    "        X_copy=X.copy()\n",
    "        for index, row in X.iterrows():\n",
    "            if row['AveragePrice'] != row['AveragePrice']: # if NaN\n",
    "                if row['region'] not in self.impute_dict:\n",
    "                    X_copy.at[index,'AveragePrice'] = self.impute_dict[row['region']]\n",
    "                else:\n",
    "                    X_copy.at[index,'AveragePrice'] = self.missing_key_val\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "35324ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    The class provides basic functionality for retrieving\n",
    "    a subset of columns from the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_names):\n",
    "        \"\"\"\n",
    "        Initialize class instance by setting\n",
    "        a list of columns to retrieve from the dataset.\n",
    "        \"\"\"\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit FeatureSelector to X, but really do nothing.\n",
    "        Return self.\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Transform X using feature selection. \n",
    "        Return column-subset of X.\n",
    "        \"\"\"\n",
    "        return X[self.feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b2387027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeUpdateTotalVolume(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Imputes value by taking mean number from certain value \n",
    "    of the 'region' column in data frame\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initalizes a new instance of imputer\n",
    "        \"\"\"\n",
    "        TransformerMixin.__init__(self)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Builds and remembers a columns with updated 'TotalVolume' values\n",
    "        Returns self\n",
    "        \"\"\"\n",
    "        self.new_total_volume = X['4046'] + X['4225'] + X['4770']\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Returns dataset with updated 'TotalVolume' column\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()\n",
    "        X_copy['Total Volume'] = self.new_total_volume\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f19a1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    The class provides functionality for converting date columns to numeric.\n",
    "    Converts dates to a number indicating the amount of time \n",
    "    that has elapsed from a certain point in time.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, timepoint, transform_to, drop):\n",
    "        \"\"\"\n",
    "        Initialize class instance by setting convert options. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        timepoint : pandas.Timestamp, \n",
    "            the time point from which the count is taken.\n",
    "        transform_to: str, \n",
    "            unit of time to use for calculating the result.\n",
    "            options:\n",
    "            - 'y' -- years;\n",
    "            - 'm' -- months;\n",
    "            - 'w' -- weeks;\n",
    "            - 'd' -- days.\n",
    "        drop: bool, \n",
    "            if True, remove the original columns from the dataset.\n",
    "        \"\"\"\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.timepoint = timepoint\n",
    "        self.transform_to = transform_to\n",
    "        self.drop = drop\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit DateTransformer to X, but really do nothing.\n",
    "        Return self.\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Transfor X using the parameters set in the constructor.\n",
    "        Return transformed dataframe. \n",
    "        \"\"\"\n",
    "        options = dict(d=1, w=7, m=30, y=365)\n",
    "        div = options.get(self.transform_to, 1)\n",
    "        columns = X.columns\n",
    "        for col in columns:\n",
    "            new_col_name = f'{col}_{self.transform_to}'\n",
    "            X[new_col_name] = X[f'{col}'].apply(\n",
    "                lambda x: (pd.to_datetime(x) - (pd.to_datetime(self.timepoint))).days / div)\n",
    "        if self.drop:\n",
    "            X.drop(columns, axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "49f715aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnDropTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Drops given columns from dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, columns, copy):\n",
    "        \"\"\"\n",
    "        Initalizes a new instance of ColumnDropTransformer\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        columns: list,\n",
    "            list of column names to delete.\n",
    "        copy: Boolean,\n",
    "            defines whether transformer will influence on\n",
    "            original dataset or not.\n",
    "        \"\"\"\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.cols_to_del=columns\n",
    "        self.copy = copy\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit ColumnDropTransformer to X, but really do nothing.\n",
    "        Return self.\n",
    "        \"\"\"\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Returns X with dropped columns\n",
    "        \"\"\"\n",
    "        if self.copy == True:\n",
    "            copy_df = X.copy()\n",
    "            for col in self.cols_to_del:\n",
    "                copy_df = copy_df.drop(col, 1)\n",
    "            return copy_df\n",
    "        else:\n",
    "            for col in self.cols_to_del:\n",
    "                X = X.drop(col, 1) \n",
    "            return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "dd2f579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnTotalSumAddTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Imputes value by taking mean number from certain value \n",
    "    of the 'region' column in data frame\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, copy=True):\n",
    "        \"\"\"\n",
    "        Creates a new instance of ColumnTotalSumAddTransformer.\n",
    "        \"\"\"\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.copy = copy\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit ColumnTotalSumAddTransformer to X, but really do nothing.\n",
    "        Return self.\n",
    "        \"\"\"\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Returns X with added 'TotalSum' column, that is\n",
    "        a product of 'TotalVolume' and 'AveragePrice'\n",
    "        \"\"\"\n",
    "        if self.copy == True:\n",
    "            copy_df = X.copy()\n",
    "            copy_df.loc[:, 'TotalSum'] = copy_df['Total Volume']*copy_df['AveragePrice']\n",
    "            return copy_df\n",
    "        else:\n",
    "            X.loc[:, 'TotalSum'] = X['Total Volume']*X['AveragePrice']\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "7c966fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyValueRowDropTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Takes out rows with specific value of a certain key\n",
    "    from dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, key, value):\n",
    "        \"\"\"\n",
    "        Initalizes a new instance of KeyValueRowDropTransformer\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        key: str,\n",
    "            key of column where to find a value.\n",
    "        value: str,\n",
    "            value to be considered.\n",
    "        \"\"\"\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit KeyValueRowDropTransformer to X, but really do nothing.\n",
    "        Return self.\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Returns X without rows with given value of a given key\n",
    "        \"\"\"\n",
    "        return X[X[self.key] != self.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "a001af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDecreaseAmountTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Decreases amount of unique values in chosen feature, ranging\n",
    "    them by other feature-estimator\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,  feature, estimator, copy=True, new_col_amount=10):\n",
    "        \"\"\"\n",
    "        Initalizes a new instance of FeatureDecreaseAmountTransformer\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature: str,\n",
    "            feature which amount of unique values is\n",
    "            need to be decreased.\n",
    "        estimator: str,\n",
    "            feature which is taken to range 'feature'.\n",
    "        new_col_amount: int,\n",
    "            amount of ranges to split 'feature'.\n",
    "            New amount of unique values will be less or equal\n",
    "            new_col_amount.\n",
    "        copy: Boolean,\n",
    "            defines whether transformer influences on\n",
    "            original dataset or not.\n",
    "        \"\"\"\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.copy = copy\n",
    "        self.new_col_amount = new_col_amount\n",
    "        self.column = feature\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fits to X by creating a new column with new\n",
    "        feature values.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()\n",
    "        size_volumes_imputer = ImputeAvPriceByRegionMean();\n",
    "        \n",
    "        X_copy = size_volumes_imputer.fit_transform(X_copy)\n",
    "        update_total_sum = ImputeUpdateTotalVolume();\n",
    "        \n",
    "        X_copy = update_total_sum.fit_transform(X_copy)\n",
    "        X_copy = X.sort_values(self.estimator)\n",
    "        \n",
    "        self.new_regions = [None]*X_copy.shape[0]\n",
    "        \n",
    "        for i in range(0, self.new_col_amount):\n",
    "            x_i = X_copy.shape[0]*i//self.new_col_amount\n",
    "            x_iplus1 = X_copy.shape[0]*(i+1)//self.new_col_amount\n",
    "            curr_prevail_region = X_copy[x_i:x_iplus1][self.column].value_counts().sort_values(ascending=False).index[0]\n",
    "            for i in range(x_i, x_iplus1):\n",
    "                self.new_regions[i] = curr_prevail_region\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Writes new feature column in X.\n",
    "        Returns transformed X.\n",
    "        \"\"\"\n",
    "        if self.copy == True:\n",
    "            copy_df = X.sort_values(self.estimator).copy()\n",
    "            copy_df[self.column] = self.new_regions\n",
    "            copy_df = copy_df.sort_index()\n",
    "            return copy_df\n",
    "        else:\n",
    "            X = X.sort_values(self.estimator)\n",
    "            X[self.column] = self.new_regions\n",
    "            X = X.sort_index()\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "acb2fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_round(X):\n",
    "    \"\"\"\n",
    "    Maps every single element in list X the following way:\n",
    "        1, if element is >= 0.5\n",
    "        0, otherwise\n",
    "    Returns mapped collection.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(X)):\n",
    "        if X[i] >= 0.5:\n",
    "            X[i] = 1\n",
    "        else:\n",
    "            X[i] = 0\n",
    "    return X\n",
    "\n",
    "def my_map(X, mapper):\n",
    "    \"\"\"\n",
    "    Maps every single element in list X using given mapper.\n",
    "    Returns mapped collection.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(X)):\n",
    "        X[i] = mapper[X[i]]\n",
    "    return X\n",
    "\n",
    "class AvocadoTypeImputer(KNNImputer):\n",
    "    \"\"\"\n",
    "    Imputes 'type' feature labels. Based on KNNImputer.\n",
    "    \"\"\"\n",
    "    def __init__(self, features):\n",
    "        \"\"\"\n",
    "        Initalizes a new instance of AvocadoTypeImputer\n",
    "        \"\"\"\n",
    "        KNNImputer.__init__(self)\n",
    "        features.append('type')\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fits to X. Maps values into numbers and says KNNImputer\n",
    "        to fit on them.\n",
    "        Return self\n",
    "        \"\"\"\n",
    "        self.type_remapper = {'conventional' : 0, 'organic' : 1}\n",
    "        X_copy = X.copy()[self.features]\n",
    "        X_copy['type'] = X['type'].map(self.type_remapper)\n",
    "        self.knn_imputer = KNNImputer()\n",
    "        self.knn_imputer.fit(X_copy)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Transforms X: says KNNImputer to transform what is previously\n",
    "        fitted, maps output back to labels.\n",
    "        Returns data frame with imputed values.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()\n",
    "        X_copy_slice = X_copy[self.features]\n",
    "        type_col_pos = X_copy_slice.columns.get_loc('type')\n",
    "\n",
    "        X_copy_slice['type'] = X_copy_slice['type'].map(self.type_remapper)\n",
    "\n",
    "        X_copy_slice = self.knn_imputer.transform(X_copy_slice)\n",
    "        type_remapper_reverse = {0: 'conventional', 1: 'organic'}\n",
    "        X_copy['type'] = my_round(X_copy_slice[:, type_col_pos])\n",
    "        X_copy['type'] = X_copy['type'].map(type_remapper_reverse)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a89d87c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNInlineImpute(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Does the exact same thing as KNNImputer, but writes\n",
    "    result in data frame in original columns\n",
    "    \"\"\"\n",
    "    def __init__(self, features):\n",
    "        \"\"\"\n",
    "        Initalizes new instance of KNNInlineImputer\n",
    "        \"\"\"\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.knn_imputer = KNNImputer()\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fits to X[features] precisely as KNNImputer\n",
    "        Returns self\n",
    "        \"\"\"\n",
    "        self.knn_imputer.fit(X[self.features])\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Transforms X[features] like KNNImputer and writes\n",
    "        result in X\n",
    "        Returns transformed X\n",
    "        \"\"\"\n",
    "        X_copy= X.copy()\n",
    "        X_copy[self.features] = self.knn_imputer.transform(X_copy[self.features])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92342d5d",
   "metadata": {},
   "source": [
    "# Building pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "9534d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('sizes_impute', KNNInlineImpute(['4046', '4225', '4770'])),\n",
    "        ('av_price_impute', ImputeAvPriceByRegionMean()),\n",
    "        ('total_volume_impute', ImputeUpdateTotalVolume()),\n",
    "        ('type_impute', AvocadoTypeImputer(features=['4046', '4225', '4770']))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "735b2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('date_selector', FeatureSelector(['Date'])),\n",
    "        ('date_transformer', DateTransformer(pd.Timestamp(2015,1,1), transform_to='m', drop=True)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "av_price_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('average_price_select', FeatureSelector(['AveragePrice']))\n",
    "    ]\n",
    ")\n",
    "\n",
    "volume_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('select_sizes_volume', FeatureSelector(['4046', '4225', '4770', 'Total Volume'])),\n",
    "    ]\n",
    ")\n",
    "\n",
    "add_columns_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('add_total_sum', ColumnTotalSumAddTransformer()),\n",
    "        ('select_total_sum', FeatureSelector(['TotalSum']))\n",
    "    ]\n",
    ")\n",
    "\n",
    "type_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('type_select_to_ohe', FeatureSelector(['type'])),\n",
    "        ('type_one_hot', OneHotEncoder(sparse=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "region_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('add_total_sum_to_range', ColumnTotalSumAddTransformer()),\n",
    "        ('region_reduce', FeatureDecreaseAmountTransformer(feature='region',\n",
    "                                                           estimator='TotalSum')),\n",
    "        ('region_select', FeatureSelector(['region'])),\n",
    "        ('region_one_hot', OneHotEncoder(sparse=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "bags_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('select_bags', FeatureSelector(['Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags']))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "aa5842e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gather_and_transform_pipeline = FeatureUnion(transformer_list=[\n",
    "    #('volumes', volume_pipeline), otherwise doesn't work for no reason,\n",
    "    # im 100% sure my imputer pipeline works properly and i've\n",
    "    # already checked whether those columns have NaN's or smth\n",
    "    # 99999 times (and they haven't)\n",
    "    ('date', date_pipeline),\n",
    "    ('av_price', av_price_pipeline),\n",
    "    ('bags', bags_pipeline),\n",
    "    ('type', type_pipeline),\n",
    "    ('region', region_pipeline)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "d8357b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('impute', impute_pipeline),\n",
    "        ('transform', gather_and_transform_pipeline)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "00e1f8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.160</td>\n",
       "      <td>55539.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.330</td>\n",
       "      <td>45371.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.500</td>\n",
       "      <td>110074.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.580</td>\n",
       "      <td>73180.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.780</td>\n",
       "      <td>44855.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>2046.96</td>\n",
       "      <td>1529.20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3576.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>1191.70</td>\n",
       "      <td>3431.50</td>\n",
       "      <td>23.224</td>\n",
       "      <td>4646.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>1191.92</td>\n",
       "      <td>2452.79</td>\n",
       "      <td>727.940</td>\n",
       "      <td>4372.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>1527.63</td>\n",
       "      <td>2981.04</td>\n",
       "      <td>727.010</td>\n",
       "      <td>5235.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>2894.77</td>\n",
       "      <td>2356.13</td>\n",
       "      <td>224.530</td>\n",
       "      <td>5475.430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          4046       4225     4770  Total Volume\n",
       "0      1036.74   54454.85   48.160     55539.750\n",
       "1       674.28   44638.81   58.330     45371.420\n",
       "2       794.70  109149.67  130.500    110074.870\n",
       "3      1132.00   71976.41   72.580     73180.990\n",
       "4       941.48   43838.39   75.780     44855.650\n",
       "...        ...        ...      ...           ...\n",
       "18244  2046.96    1529.20    0.000      3576.160\n",
       "18245  1191.70    3431.50   23.224      4646.424\n",
       "18246  1191.92    2452.79  727.940      4372.650\n",
       "18247  1527.63    2981.04  727.010      5235.680\n",
       "18248  2894.77    2356.13  224.530      5475.430\n",
       "\n",
       "[18249 rows x 4 columns]"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "5979b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd4ceb2",
   "metadata": {},
   "source": [
    "Now lets use preprocessed data to try to \"predict\" something\n",
    "(as we are only expected to try out api, data will be random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "47d9b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc(method, ctor_params, params, preparation):\n",
    "    \"\"\"\n",
    "    Function builds pipeline of full data preparation and launches grid search\n",
    "    with parameters passed in `params`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    method: <class 'type'>,\n",
    "        class (type/method) for boosting classification.\n",
    "    ctor_params: dict,\n",
    "        parameters for `method` initialization (__init__ method).\n",
    "    params: list of dict,\n",
    "        grid definition for GridSearchCV.\n",
    "    preparation: pipeline, transformer,\n",
    "        preparation step for pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    pip = Pipeline(\n",
    "        steps=[\n",
    "            ('preparation', preparation),\n",
    "            ('gc', GridSearchCV(method(**ctor_params), params, n_jobs=-1,\n",
    "                                scoring='accuracy', cv=5, refit=True, verbose=2))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    df = pd.read_csv('avocado.csv')\n",
    "    df = df.dropna()\n",
    "    X_train = df[::2][0:8000]\n",
    "    X_test = df[1::2][0:8000]\n",
    "    y_train = [random.randint(0,100) for i in range(0, X_train.shape[0])]\n",
    "    y_test = [random.randint(0,100) for i in range(0, X_test.shape[0])]\n",
    "    \n",
    "    pip.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test, pip.predict(X_test)\n",
    "    \n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print('Best params found:\\n', pip['gc'].best_params_)\n",
    "    return pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "d71e68c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.04      0.02        76\n",
      "           1       0.01      0.05      0.01        62\n",
      "           2       0.01      0.07      0.02        80\n",
      "           3       0.01      0.03      0.01        76\n",
      "           4       0.02      0.07      0.03        72\n",
      "           5       0.01      0.03      0.01        97\n",
      "           6       0.02      0.06      0.03        83\n",
      "           7       0.01      0.02      0.01        97\n",
      "           8       0.02      0.05      0.02        83\n",
      "           9       0.00      0.01      0.01        85\n",
      "          10       0.02      0.05      0.03        83\n",
      "          11       0.00      0.01      0.01        70\n",
      "          12       0.01      0.03      0.01        79\n",
      "          13       0.01      0.03      0.01        65\n",
      "          14       0.02      0.05      0.03        74\n",
      "          15       0.01      0.03      0.01        76\n",
      "          16       0.00      0.00      0.00        66\n",
      "          17       0.00      0.00      0.00        73\n",
      "          18       0.02      0.04      0.03        76\n",
      "          19       0.01      0.03      0.01        62\n",
      "          20       0.01      0.03      0.02        68\n",
      "          21       0.01      0.01      0.01        78\n",
      "          22       0.01      0.01      0.01        84\n",
      "          23       0.00      0.00      0.00        81\n",
      "          24       0.02      0.04      0.02        79\n",
      "          25       0.02      0.03      0.02        80\n",
      "          26       0.01      0.01      0.01        91\n",
      "          27       0.01      0.02      0.01        65\n",
      "          28       0.00      0.00      0.00        62\n",
      "          29       0.02      0.02      0.02        89\n",
      "          30       0.01      0.01      0.01        68\n",
      "          31       0.00      0.00      0.00        85\n",
      "          32       0.01      0.01      0.01        94\n",
      "          33       0.00      0.00      0.00        81\n",
      "          34       0.02      0.02      0.02        89\n",
      "          35       0.04      0.03      0.03        78\n",
      "          36       0.00      0.00      0.00        84\n",
      "          37       0.03      0.02      0.03        85\n",
      "          38       0.02      0.02      0.02        62\n",
      "          39       0.00      0.00      0.00        99\n",
      "          40       0.01      0.01      0.01        78\n",
      "          41       0.03      0.01      0.02        75\n",
      "          42       0.00      0.00      0.00        76\n",
      "          43       0.06      0.02      0.03        82\n",
      "          44       0.00      0.00      0.00       100\n",
      "          45       0.03      0.01      0.02        74\n",
      "          46       0.00      0.00      0.00        80\n",
      "          47       0.00      0.00      0.00        89\n",
      "          48       0.00      0.00      0.00        83\n",
      "          49       0.00      0.00      0.00        76\n",
      "          50       0.00      0.00      0.00        83\n",
      "          51       0.00      0.00      0.00        66\n",
      "          52       0.00      0.00      0.00        73\n",
      "          53       0.00      0.00      0.00        86\n",
      "          54       0.00      0.00      0.00        84\n",
      "          55       0.12      0.02      0.04        97\n",
      "          56       0.00      0.00      0.00        94\n",
      "          57       0.00      0.00      0.00        91\n",
      "          58       0.00      0.00      0.00        80\n",
      "          59       0.00      0.00      0.00        83\n",
      "          60       0.00      0.00      0.00        73\n",
      "          61       0.00      0.00      0.00        83\n",
      "          62       0.00      0.00      0.00        69\n",
      "          63       0.04      0.01      0.02        78\n",
      "          64       0.00      0.00      0.00        89\n",
      "          65       0.00      0.00      0.00       105\n",
      "          66       0.00      0.00      0.00        91\n",
      "          67       0.00      0.00      0.00        80\n",
      "          68       0.00      0.00      0.00        78\n",
      "          69       0.00      0.00      0.00        80\n",
      "          70       0.00      0.00      0.00        78\n",
      "          71       0.00      0.00      0.00        80\n",
      "          72       0.00      0.00      0.00        86\n",
      "          73       0.00      0.00      0.00        75\n",
      "          74       0.00      0.00      0.00        86\n",
      "          75       0.00      0.00      0.00        71\n",
      "          76       0.00      0.00      0.00        70\n",
      "          77       0.00      0.00      0.00        77\n",
      "          78       0.00      0.00      0.00        83\n",
      "          79       0.00      0.00      0.00        72\n",
      "          80       0.00      0.00      0.00        71\n",
      "          81       0.05      0.01      0.02        91\n",
      "          82       0.00      0.00      0.00        81\n",
      "          83       0.00      0.00      0.00        86\n",
      "          84       0.00      0.00      0.00        66\n",
      "          85       0.00      0.00      0.00        86\n",
      "          86       0.00      0.00      0.00        70\n",
      "          87       0.00      0.00      0.00        68\n",
      "          88       0.00      0.00      0.00        71\n",
      "          89       0.00      0.00      0.00        87\n",
      "          90       0.10      0.01      0.02        81\n",
      "          91       0.00      0.00      0.00        82\n",
      "          92       0.00      0.00      0.00        63\n",
      "          93       0.00      0.00      0.00        78\n",
      "          94       0.00      0.00      0.00        72\n",
      "          95       0.00      0.00      0.00        70\n",
      "          96       0.00      0.00      0.00        81\n",
      "          97       0.00      0.00      0.00        79\n",
      "          98       0.00      0.00      0.00        77\n",
      "          99       0.00      0.00      0.00        81\n",
      "         100       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.01      8000\n",
      "   macro avg       0.01      0.01      0.01      8000\n",
      "weighted avg       0.01      0.01      0.01      8000\n",
      "\n",
      "Best params found:\n",
      " {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preparation',\n",
       "                 Pipeline(steps=[('impute',\n",
       "                                  Pipeline(steps=[('sizes_impute',\n",
       "                                                   <__main__.KNNInlineImpute object at 0x00000229002A28E0>),\n",
       "                                                  ('av_price_impute',\n",
       "                                                   <__main__.ImputeAvPriceByRegionMean object at 0x00000229002A2E80>),\n",
       "                                                  ('total_volume_impute',\n",
       "                                                   <__main__.ImputeUpdateTotalVolume object at 0x00000229002A2760>),\n",
       "                                                  ('type_impute',\n",
       "                                                   AvocadoTypeImputer(featu...\n",
       "                                                                                   <__main__.ColumnTotalSumAddTransformer object at 0x0000022900274BE0>),\n",
       "                                                                                  ('region_reduce',\n",
       "                                                                                   <__main__.FeatureDecreaseAmountTransformer object at 0x0000022900274D30>),\n",
       "                                                                                  ('region_select',\n",
       "                                                                                   FeatureSelector(feature_names=['region'])),\n",
       "                                                                                  ('region_one_hot',\n",
       "                                                                                   OneHotEncoder(sparse=False))]))]))])),\n",
       "                ('gc',\n",
       "                 GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "                              param_grid={}, scoring='accuracy', verbose=2))])"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc(KNeighborsClassifier, {}, {}, full_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674efe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
